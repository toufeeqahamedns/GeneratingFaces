{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"face2text.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"PXciFOVHRhx3","colab_type":"code","colab":{}},"cell_type":"code","source":["!rm -rf T2F\n","!git clone https://github.com/fedor-chervinskii/T2F.git"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OFknAIykoQ9S","colab_type":"code","colab":{}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ziIY-pcdywIi","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir /content/T2F/implementation/networks/InferSent/models"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"d3ZvnqYcbUCQ","colab":{}},"cell_type":"code","source":["!cp /content/gdrive/My\\ Drive/T2F/infersent2.pkl /content/T2F/implementation/networks/InferSent/models/infersent2.pkl\n","#!curl -Lo /content/T2F/implementation/networks/InferSent/models/infersent2.pkl https://dl.fbaipublicfiles.com/infersent/infersent2.pkl"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"6vApvNaubTSN","colab":{}},"cell_type":"code","source":["!ls -lah /content/T2F/implementation/networks/InferSent/models/infersent2.pkl"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ofceeymwb6TW","colab_type":"code","colab":{}},"cell_type":"code","source":["#!wget http://nlp.stanford.edu/data/glove.840B.300d.zip\n","!unzip glove.840B.300d.zip\n","!mv glove.840B.300d.txt /content/T2F/implementation/networks/InferSent/models/glove.840B.300d.txt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DM8XAgjC-lUU","colab_type":"code","colab":{}},"cell_type":"code","source":["!mv glove.840B.300d.txt /content/T2F/implementation/networks/InferSent/models/glove.840B.300d.txt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mlOVy4BU2pEw","colab_type":"code","colab":{}},"cell_type":"code","source":["!cp /content/T2F/implementation/networks/InferSent/models/glove.840B.300d.txt /content/gdrive/My\\ Drive/T2F/glove.840B.300d.txt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kHj9d1GIRvkW","colab_type":"code","colab":{}},"cell_type":"code","source":["!wget http://vis-www.cs.umass.edu/lfw/lfw.tgz\n","!tar -xf lfw.tgz"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2k0hZ8A-fUMf","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install -r T2F/requirements.txt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Cbx6loVsJyt9","colab_type":"code","colab":{}},"cell_type":"code","source":["!nvcc --version"],"execution_count":0,"outputs":[]},{"metadata":{"id":"A-_he3kypRgu","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip uninstall -y torch\n","!pip install https://download.pytorch.org/whl/cu100/torch-1.0.0-cp36-cp36m-linux_x86_64.whl\n","#!pip install torch==0.4.0"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_NBRf0WLSaMl","colab_type":"code","colab":{}},"cell_type":"code","source":["import sys\n","sys.path.append('/content/T2F/implementation')\n","sys.path.append('/content/T2F/')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vSRhcaaUSi5o","colab_type":"code","colab":{}},"cell_type":"code","source":["from train_network import main as main_train\n","from train_network import get_config"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D6rNobaJTaW0","colab_type":"code","colab":{}},"cell_type":"code","source":["import argparse\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument(\"--config\", action=\"store\", type=str, default=\"/content/T2F/implementation/configs/2_colab.conf\",\n","                    help=\"default configuration for the Network\")\n","parser.add_argument(\"--start_depth\", action=\"store\", type=int, default=0,\n","                    help=\"Starting depth for training the network\")\n","parser.add_argument(\"--encoder_file\", action=\"store\", type=str, default=None,\n","                    help=\"pretrained Encoder file (compatible with my code)\")\n","parser.add_argument(\"--ca_file\", action=\"store\", type=str, default=None,\n","                    help=\"pretrained Conditioning Augmentor file (compatible with my code)\")\n","parser.add_argument(\"--generator_file\", action=\"store\", type=str, default=None,\n","                    help=\"pretrained Generator file (compatible with my code)\")\n","parser.add_argument(\"--discriminator_file\", action=\"store\", type=str, default=None,\n","                    help=\"pretrained Discriminator file (compatible with my code)\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ghS9RsLxTkKG","colab_type":"code","colab":{}},"cell_type":"code","source":["args = parser.parse_args([])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vM8DgMpwVlvM","colab_type":"code","colab":{}},"cell_type":"code","source":["config = get_config(args.config)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jjaneT7eV5E3","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch as th\n","\n","class ConditionAugmentor(th.nn.Module):\n","    \"\"\" Perform conditioning augmentation\n","        from the paper -> https://arxiv.org/abs/1710.10916 (StackGAN++)\n","        uses the reparameterization trick from VAE paper.\n","    \"\"\"\n","\n","    def __init__(self, input_size, latent_size, use_eql=True, device=th.device(\"cpu\")):\n","        \"\"\"\n","        constructor of the class\n","        :param input_size: input size to the augmentor\n","        :param latent_size: required output size\n","        :param use_eql: boolean for whether to use equalized learning rate\n","        :param device: device on which to run the Module\n","        \"\"\"\n","        super(ConditionAugmentor, self).__init__()\n","\n","        assert latent_size % 2 == 0, \"Latent manifold has odd number of dimensions\"\n","\n","        # state of the object\n","        self.device = device\n","        self.input_size = input_size\n","        self.latent_size = latent_size\n","\n","        # required modules:\n","        if use_eql:\n","            from pro_gan_pytorch.CustomLayers import _equalized_linear\n","            self.transformer = _equalized_linear(self.input_size, 2 * self.latent_size).to(device)\n","        else:\n","            self.transformer = th.nn.Linear(self.input_size, 2 * self.latent_size).to(device)\n","\n","    def forward(self, x, epsilon=1e-12):\n","        \"\"\"\n","        forward pass (computations)\n","        :param x: input\n","        :param epsilon: a small noise added for numerical stability\n","        :return: c_not_hat, mus, sigmas => augmented text embeddings, means, stds\n","        \"\"\"\n","        from torch.nn.functional import relu\n","\n","        # apply the feed forward layer:\n","        combined = self.transformer(x)\n","\n","        # use the reparameterization trick\n","        mid_point = self.latent_size\n","        mus, sigmas = combined[:, :mid_point], combined[:, mid_point:]\n","\n","        # mus don't need to be transformed, but sigmas cannot be negative.\n","        # so, we'll apply a ReLU on top of sigmas\n","        sigmas = relu(sigmas)  # hopefully the network will learn a good sigma mapping\n","        sigmas = sigmas + epsilon  # small noise added for stability\n","\n","        epsilon = th.randn(*mus.shape).to(self.device)\n","        c_not_hat = (epsilon * sigmas) + mus\n","\n","        return c_not_hat, mus, sigmas\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"81U0c57PXKvc","colab_type":"code","colab":{}},"cell_type":"code","source":["device = 'cuda'\n","\n","import data_processing.DataLoader as dl\n","\n","dataset = dl.RawTextFace2TextDataset(\n","    annots_file=config.annotations_file,\n","    img_dir=config.images_dir,\n","    img_transform=dl.get_transform(config.img_dims)\n",")\n","from networks.TextEncoder import PretrainedEncoder\n","# create a new session object for the pretrained encoder:\n","text_encoder = PretrainedEncoder(\n","    model_file=config.pretrained_encoder_file,\n","    embedding_file=config.pretrained_embedding_file,\n","    device=device\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CXA8PYnUb0H2","colab_type":"code","colab":{}},"cell_type":"code","source":["text_encoder = PretrainedEncoder(\n","    model_file=config.pretrained_encoder_file,\n","    embedding_file=config.pretrained_embedding_file,\n","    device=device\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vBLwHSoZVvYR","colab_type":"code","colab":{}},"cell_type":"code","source":["condition_augmenter = ConditionAugmentor(\n","    input_size=config.hidden_size,\n","    latent_size=config.ca_out_size,\n","    use_eql=config.use_eql,\n","    device='cuda'\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"f0HanvoGcFLq","colab_type":"code","colab":{}},"cell_type":"code","source":["temp_data = dl.get_data_loader(dataset, 64, num_workers=3)\n","fixed_captions, fixed_real_images = iter(temp_data).next()\n","fixed_embeddings = text_encoder(fixed_captions)\n","fixed_embeddings.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Lx8B23iRXyBM","colab_type":"code","colab":{}},"cell_type":"code","source":["condition_augmenter.train()\n","\n","# create fixed_input for debugging\n","temp_data = dl.get_data_loader(dataset, 64, num_workers=3)\n","fixed_captions, fixed_real_images = iter(temp_data).next()\n","fixed_embeddings = text_encoder(fixed_captions)\n","fixed_embeddings = th.from_numpy(fixed_embeddings).to(device)\n","\n","fixed_c_not_hats, _, _ = condition_augmenter(fixed_embeddings)\n","\n","fixed_noise = th.randn(len(fixed_captions),\n","                       config.latent_size - fixed_c_not_hats.shape[-1]).to(device)\n","\n","fixed_gan_input = th.cat((fixed_c_not_hats, fixed_noise), dim=-1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Lu64dCDPYhvE","colab_type":"code","colab":{}},"cell_type":"code","source":["fixed_embeddings.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YPeVD0YEUkaD","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","torch.load('/content/T2F/implementation/networks/InferSent/models/infersent2.pkl')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"V14VfURS-WpR","colab_type":"code","colab":{}},"cell_type":"code","source":["from networks.TextEncoder import PretrainedEncoder\n","# create a new session object for the pretrained encoder:\n","text_encoder = PretrainedEncoder(\n","    model_file='/content/T2F/implementation/networks/InferSent/models/infersent2.pkl',\n","    embedding_file='/content/T2F/implementation/networks/InferSent/models/glove.840B.300d.txt',\n","    device='cuda'\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"t9_kOYTVTA0F","colab_type":"code","colab":{}},"cell_type":"code","source":["main_train(args)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"s_HClw096hTO","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QmHng2xUdkZb","colab_type":"code","colab":{}},"cell_type":"code","source":["for i in range(4, 5):\n","  log = pd.read_csv('/content/gdrive/My Drive/T2F/training_runs/2/losses/loss_{}.log'.format(i), delimiter='\\t', header=None, names=['d_loss', 'g_loss', 'kl_loss'])\n","  n = len(log.d_loss)\n","  xs = list(range(n*i, n*(i + 1)))\n","  plt.plot(xs, log.d_loss)\n","  plt.plot(xs, log.g_loss)\n","  plt.plot(xs, log.kl_loss)\n","  plt.legend(log.columns)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KFDckiiOd64t","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Mgfk0I5teAJp","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.plot(log.d_loss)\n","plt.plot(log.g_loss)\n","plt.plot(log.kl_loss)\n","plt.legend(log.columns)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oMSFK0S_kDvE","colab_type":"code","colab":{}},"cell_type":"code","source":["from networks.ConditionAugmentation import ConditionAugmentor\n","from pro_gan_pytorch.PRO_GAN import ConditionalProGAN\n","\n","import numpy as np\n","\n","def create_grid(samples, scale_factor, img_file, real_imgs=False):\n","    \"\"\"\n","    utility function to create a grid of GAN samples\n","    :param samples: generated samples for storing\n","    :param scale_factor: factor for upscaling the image\n","    :param img_file: name of file to write\n","    :param real_imgs: turn off the scaling of images\n","    :return: None (saves a file)\n","    \"\"\"\n","    from torchvision.utils import save_image\n","    from torch.nn.functional import interpolate\n","\n","    samples = th.clamp((samples / 2) + 0.5, min=0, max=1)\n","\n","    # upsample the image\n","    if not real_imgs and scale_factor > 1:\n","        samples = interpolate(samples,\n","                              scale_factor=scale_factor)\n","\n","    # save the images:\n","    save_image(samples, img_file, nrow=int(np.sqrt(len(samples))))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"00zS7WSfe4K7","colab_type":"code","colab":{}},"cell_type":"code","source":["# create the networks\n","\n","condition_augmenter = ConditionAugmentor(\n","    input_size=config.hidden_size,\n","    latent_size=config.ca_out_size,\n","    use_eql=config.use_eql,\n","    device=device\n",")\n","\n","ca_file = '/content/gdrive/My Drive/T2F/training_runs/2/saved_models/Condition_Augmentor_4.pth'\n","\n","print(\"Loading conditioning augmenter from:\", ca_file)\n","condition_augmenter.load_state_dict(th.load(ca_file))\n","\n","c_pro_gan = ConditionalProGAN(\n","    embedding_size=config.hidden_size,\n","    depth=config.depth,\n","    latent_size=config.latent_size,\n","    compressed_latent_size=config.compressed_latent_size,\n","    learning_rate=config.learning_rate,\n","    beta_1=config.beta_1,\n","    beta_2=config.beta_2,\n","    eps=config.eps,\n","    drift=config.drift,\n","    n_critic=config.n_critic,\n","    use_eql=config.use_eql,\n","    loss=config.loss_function,\n","    use_ema=config.use_ema,\n","    ema_decay=config.ema_decay,\n","    device=device\n",")\n","\n","generator_file = '/content/gdrive/My Drive/T2F/training_runs/2/saved_models/GAN_GEN_4.pth'\n","print(\"Loading generator from:\", generator_file)\n","c_pro_gan.gen.load_state_dict(th.load(generator_file))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"z-GiHK96jkHT","colab_type":"code","colab":{}},"cell_type":"code","source":["condition_augmenter.train(False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kcJ9nQlqkjAt","colab_type":"code","colab":{}},"cell_type":"code","source":["temp_data = dl.get_data_loader(dataset, 1, num_workers=3)\n","fixed_captions, fixed_real_images = iter(temp_data).next()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YqAo6jbjnryC","colab_type":"code","colab":{}},"cell_type":"code","source":["fixed_embeddings = text_encoder(fixed_captions)\n","fixed_embeddings = th.from_numpy(fixed_embeddings).to(device)\n","\n","fixed_c_not_hats, mus, _ = condition_augmenter(fixed_embeddings)\n","\n","fixed_noise = th.zeros(len(fixed_captions),\n","                       c_pro_gan.latent_size - fixed_c_not_hats.shape[-1]).to(device)\n","\n","fixed_gan_input = th.cat((fixed_c_not_hats, fixed_noise), dim=-1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"s40jvXiqmjcb","colab_type":"code","colab":{}},"cell_type":"code","source":["create_grid(\n","    samples=c_pro_gan.gen(\n","        fixed_gan_input,\n","        4,\n","        1.0\n","    ),\n","    scale_factor=1,\n","    img_file='output.png')\n","\n","img = plt.imread('output.png')\n","plt.figure()\n","plt.imshow(img)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GNlqaQErnQ2L","colab_type":"code","colab":{}},"cell_type":"code","source":["fixed_captions"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CRoWBY-Bn5zh","colab_type":"code","colab":{}},"cell_type":"code","source":["fixed_embeddings.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_Rs4KX4Wn9b1","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}