
# All paths to different required data objects
images_dir: "../data/LFW/lfw"
processed_text_file: "processed_annotations/processed_text.pkl"
log_dir: "training_runs/6/losses/"
sample_dir: "training_runs/6/generated_samples/"
save_dir: "training_runs/6/saved_models/"

# Hyperparameters for the Model
captions_length: 100
img_dims:
  - 256
  - 256

# LSTM hyperparameters
embedding_size: 128
hidden_size: 256
num_layers: 3  # number of LSTM cells in the encoder network

# Conditioning Augmentation hyperparameters
ca_out_size: 224

# Pro GAN hyperparameters
depth: 7
latent_size: 256
learning_rate: 0.001
beta_1: 0
beta_2: 0
eps: 0.00000001
drift: 0.001
n_critic: 1

# Training hyperparameters:
epochs:
  - 10
  - 20
  - 40
  - 80
  - 160
  - 320
  - 640

# % of epochs for fading in the new layer
fade_in_percentage:
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100

batch_sizes:
  - 16
  - 16
  - 16
  - 16
  - 16
  - 16
  - 16

num_workers: 3
feedback_factor: 10  # number of logs generated per epoch
checkpoint_factor: 2  # save the models after these many epochs
